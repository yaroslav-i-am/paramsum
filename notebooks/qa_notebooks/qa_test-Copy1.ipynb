{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046f1c4c-61e0-4b16-9090-ebf2c593adae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = device(type='cuda')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\envs\\kaggle\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{DEVICE = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e9ac5a-71db-4d7d-835d-e80dd0088c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\anaconda3\\envs\\kaggle\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\envs\\kaggle\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "D:\\ProgramData\\anaconda3\\envs\\kaggle\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "D:\\ProgramData\\anaconda3\\envs\\kaggle\\lib\\site-packages\\accelerate\\utils\\modeling.py:1363: UserWarning: Current model requires 109055232 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10eadb16bef4b85847f29a4c1c14125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "D:\\ProgramData\\anaconda3\\envs\\kaggle\\lib\\site-packages\\transformers\\generation\\utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, me hearties! I be Captain Chat, the scurviest chatbot to ever sail the seven seas! I be here to help ye with yer questions and troubles, so hoist the colors and let's set sail fer a swashbucklin' good time!\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=\"IlyaGusev/saiga_llama3_8b\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"IlyaGusev/saiga_llama3_8b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6357374c-7458-4401-84c0-bead133d8197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В отзыве есть информация о декорациях в фильме: \"Картина снята в жанре драмы, повествующей о жизни и особенностях американской тюрьмы прошлого века...\"\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Тебе дан отзыв на фильм. Найди в отзыве информацию о декорациях в фильме. Если информации о декорациях нет, скажи, что такой информации нет.\"},\n",
    "    {\"role\": \"user\", \"content\": \"'Культовый шедевр кинематографа, снятый в 1994 году Фрэнком Дарабонтом по повести Стивена Кинга — « Рита Хейуорт и спасение из Шоушенка». Фильм был удостоен номинироваться на престижнейшие награды в мире кинематографа и по сей день занимать лидирующие позиции в рейтингах лучших картин всех времен.         Картина снята в жанре драмы, повествующей о жизни и особенностях американской тюрьмы прошлого века, подробно описывая и раскрывая типажи ее обитателей и руководства, с которыми столкнется главный герой. Фильм будет сохранять достаточное количество интриг одна из которых — действительно ли виновен главный герой в преступлении из за которого он очутился в столь жутком месте?.         Сюжет данного фильма, является главным фактором в его шедевральной красоте, который покорит зрителя колоссальным интересом с первых минут фильма и введет аудиторию в незабываемое состояние в которой будет сохранять ее и до самого конца. Помимо огромнейшего интереса, который возникнет у зрителя, картина раскроет множество интриг и секретов представших в фильме что также приведет зрителя в незабываемый восторг. А показ человеческих переживаний, чувств, взаимоотношений и позиции людей находящихся в этом месте, заставит задуматься и переосмыслить.         Актерский состав порадует наличием Тима Роббинса и Моргана Фримана, сыгравших в данной картине главные роли. Они превосходно сыграли и раскрыли своих интереснейших персонажей, покоряющих своей своеобразностью и неповторимостью, с которыми аудитория сможет ознакомиться по ходу фильма, несомненно являющимся восхитительным и благодаря данному аспекту.         Работа режиссера вместе с командой — художников, оператора и монтажиста, дадут картине прекрасное изображение и качественную сьемку, придающих фильму еще большей красоты.         Прекрасный фильм с наличием всех главнейших факторов выполненных на высочайшем уровне, фильм который подарит незабываемые впечатления и обязательно приведет в восторг. Вот он шедевр киноискусства! Приятного просмотра!         10 из 10'\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e11686-0bf5-4a2a-89b9-77d6db89b420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffacd2c-90d8-4b1d-9401-ae9809165226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efae80-b885-4755-afc5-e2c57046186b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6811d374-4af1-4560-b1ae-f3fc8511837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Расскажи сказку! Говори, как будто я ребёнок!'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('Расскажи сказку! Говори, как будто я ребёнок')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb362f6-a5a6-4371-81dd-7f188c235ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 1536,\n",
      "  \"no_repeat_ngram_size\": 15,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.2,\n",
      "  \"top_k\": 40,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "print(generation_config)\n",
    "\n",
    "inputs = [\"Почему трава зеленая?\", \"Сочини длинный рассказ, обязательно упоминая следующие объекты. Дано: Таня, мяч\"]\n",
    "for inp in inputs:\n",
    "    conversation = Conversation()\n",
    "    conversation.add_user_message(inp)\n",
    "    prompt = conversation.get_prompt(tokenizer)\n",
    "\n",
    "    output = generate(model, tokenizer, prompt, generation_config)\n",
    "    print(inp)\n",
    "    print(output)\n",
    "    print()\n",
    "    print(\"==============================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e49e9ebf-7bd1-4cdb-9068-cdf8041b9189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>.\n",
      "\n",
      "И вот, когда я уже почти совсем собрался, в дверь постучали.\n",
      "\n",
      "- Кто там? - спросил я.\n",
      "\n",
      "- Это я, - ответил голос.\n",
      "\n",
      "- Кто? - переспросил я.\n",
      "\n",
      "- Это я, - повторил голос.\n",
      "\n",
      "- Кто? - спросил я.\n",
      "\n",
      "- Это я, - ответил голос.\n",
      "\n",
      "- Кто? - спросил я.\n",
      "\n",
      "- Это я, - ответил голос.\n",
      "\n",
      "- Кто? - спросил я.\n",
      "\n",
      "- Это я, - ответил голос.\n",
      "\n",
      "- Кто? - спросил я.\n",
      "\n",
      "- Это я, - ответил голос.\n",
      "\n",
      "- Кто? - спросил я.\n",
      "\n",
      "- Это я, - ответил голос.\n",
      "\n",
      "- Кто? - спросил я.\n",
      "\n",
      "- Это я, - ответил голос.</s>\n"
     ]
    }
   ],
   "source": [
    "lm_text='2 + 2 ='\n",
    "input_ids=torch.tensor([tokenizer.encode(lm_text)]).to(device)\n",
    "outputs=model.generate(input_ids,eos_token_id=tokenizer.eos_token_id,early_stopping=True,max_length=200)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac706dc3-1b1b-4b88-ad83-2d3779fe2ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скажи, Вкусные пряники?\n",
      "tensor([[10162,     3,    32,  2578,    66,  4139,   840,    25,     2]])\n",
      "Скажи, Вкусные пряники?</s>\n",
      "\n",
      "output_ids = tensor([[    0, 32099,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]])\n",
      ",,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Скажи, Вкусные пряники?\"\n",
    "input_ids = tokenizer(\n",
    "    [input_text], \n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=True\n",
    "    \n",
    ").input_ids\n",
    "print(input_text, input_ids, tokenizer.decode(input_ids[0]), sep='\\n', end='\\n\\n')\n",
    "\n",
    "output_ids = model.generate(input_ids)\n",
    "print(f'{output_ids = }')\n",
    "output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04c21d48-df33-4d32-bc58-32e755df1e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скажи\n",
      ",\n",
      "В\n",
      "кус\n",
      "ные\n",
      "пря\n",
      "ники\n",
      "?\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "for el in input_ids[0]:\n",
    "    print(tokenizer.decode(torch.tensor([el])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdd3dcc-86e6-419d-868d-3a8b1b0108fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yaroslav</td>\n",
       "      <td>Pristalov</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name    surname\n",
       "0  Yaroslav  Pristalov"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={'name': ['Yaroslav'], 'surname': ['Pristalov']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4d456-c359-4899-9ec8-da318d5b3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
